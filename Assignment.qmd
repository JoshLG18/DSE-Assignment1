---
title: "Question 3 + 4"
author: "720017170"
format: pdf
execute:
    echo: false
    warning: false
    message: false
    results: false
header-includes:
    - \usepackage{float}   
---

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr
from scipy.optimize import curve_fit
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.preprocessing import PolynomialFeatures
```

### Question 3 - See .qmd for all code

**(a) Import each dataset into memory as a separate data frame, keeping all countries as your sample.**

```{python}
#| echo: true

plt.rcParams.update({'font.size': 14})

# Loading in the Data
Health_Data = pd.read_csv('Data/Health.csv', index_col=None)
Infant_Data = pd.read_csv("Data/Infant.csv",index_col=None)

# Replace .. with NA
Health_Data.replace("..", pd.NA, inplace=True)
Infant_Data.replace("..", pd.NA, inplace=True)

# Removing unnecessary columns
Health_Data = Health_Data.drop(columns=['Series Name', 'Series Code'])
Infant_Data = Infant_Data.drop(columns=['Series Name', 'Series Code'])

# Remove names in []
Health_Data.columns = Health_Data.columns.str.replace(r'\[.*\]', '', regex=True)
Infant_Data.columns = Infant_Data.columns.str.replace(r'\[.*\]', '', regex=True)

print(Infant_Data.head())
print(Health_Data.head())
```

\newpage

**(b) If data are not already stored in this way, please reshape data so that they consist of a single line of data for each country and year.**

```{python}
#| echo: true

# Pivoting the Data into a long format
Health_Data_long = pd.melt(Health_Data, 
        id_vars=['Country Name', 'Country Code'], 
        var_name='Year', 
        value_name='Heathcare Expenditure (USD)')
Infant_Data_long = pd.melt(Infant_Data, 
        id_vars=['Country Name', 'Country Code'], 
        var_name='Year', 
        value_name='Infant Mortality Rates (per 1,000 live births)')
```

```{python}
Health_Data_long.head() # Print the first 5 rows of the pivoted dataset
```

```{python}
Infant_Data_long.head() # Print the first 5 rows of the pivoted dataset
```

**(c) Calculate the total number of countries observed in each data frame Calculate the total number of years observed in each data frame.**

```{python}
#| echo: true

# Counts the number of unique contries
num_countries_FDI = Health_Data_long["Country Name"].nunique() 

# Outputs the number of unique countries using an f string
print(f"Total number of unique countries in Health_Data: {num_countries_FDI}")

num_years_FDI = Health_Data_long["Year"].nunique() # Counts the number of unique years
print(f"Total number of unique years observed in Health_Data: {num_years_FDI}")

num_countries_GDP = Infant_Data_long["Country Name"].nunique()
print(f"Total number of unique countries in Infant_Data: {num_countries_GDP}")

num_years_GDP = Infant_Data_long["Year"].nunique()
print(f"Total number of unique years observed in Infant_Data: {num_years_GDP}")
```

**(d) Calculate the number of observations for which data is missing**

```{python}
#| echo: true

# Sums the number of missing values in each dataset
missing_values_Health = Health_Data_long.isna().sum().sum()
print(f"Total missing observations in Health_Data: {missing_values_Health}")

missing_values_Infant = Infant_Data_long.isna().sum().sum()
print(f"Total missing observations in Infant_Data: {missing_values_Infant}")
```

**(e) Join the two files by country and year so that you have single dataframe containing both variables. Explain clearly what type of join this is, and carefully check that the number of observations resulting from the join makes sense.**

```{python}
#| echo: true

# Merge the data on Country Name, Country code and Year
merged_data = pd.merge(Health_Data_long, Infant_Data_long, on=['Country Name', 
'Country Code', 'Year'])
print(merged_data.head())

# Print the number of rows in the DataFrame
num_rows = merged_data.shape[0]
print(f"Number of rows in the DataFrame: {num_rows}")
```

The join completed in the above code chunk is an inner join and only keeps rows that exist in both Health_Data_long and Infant_Data_long. If a country or year exists in one dataset but not the other, it will be dropped.

\newpage

### Question 4 - Investigating the Relationship Between Current Healthcare Expenditure per Capita and Infant Mortality Rates from 2000 - 2022

**Missing Data**

```{python}

# Create a dataframe showing the number of missing values for each dataset
missing_values_table = pd.DataFrame({
    'Variable': ['Health Expenditure', 'Infant Mortality Rate'],
    'Total Missing Observations': [missing_values_Health, missing_values_Infant],
    'Percentage of Missing Observations': [
        round((missing_values_Health / len(Health_Data_long)) * 100, 1),
        round((missing_values_Infant / len(Infant_Data_long)) * 100, 1)
    ]
})

# Ensure percentages are rounded properly and formatted as strings
missing_values_table['Percentage of Missing Observations'] = missing_values_table['Percentage of Missing Observations'].apply(lambda x: f"{x:.1f}")

# Convert DataFrame to LaTeX format
latex_table = missing_values_table.to_latex(index=False,
                                            caption="Missing Observations of Variables",
                                            label="Table 1:missings",
                                            column_format="lrr",
                                            escape=False)

# Ensure correct table float positioning
latex_table = latex_table.replace("\\begin{table}", "\\begin{table}[H]")

# Insert table counter reset before the table
latex_reset = "\\setcounter{table}{0}\n"

# Append reset command to LaTeX table
latex_table = latex_reset + latex_table

# Save LaTeX table with reset command
with open("missing_table.tex", "w") as f:
    f.write(latex_table)
```

\input{missing_table.tex}

Both datasets contained a large amount of missing data, illustrated in Table 1. Potentially due to countries not collecting the data or collecting the data at different year intervals. Missing data can have an impact on data analysis if not handled properly and can lead to incorrect conclusions. The year 2023 contained no data; therefore, this column was dropped. To deal with the other missing data, I decided to drop all rows containing missing data, sometimes, this could result in a significant reduction of sample size; however, in this case with observational data, 1099 observations were removed (21.1% of the dataset) and only 27 countries were dropped, indicating this was an effective method to handling missing data as there were still 4109 observations. An alternative approach would’ve been mean, multiple or regression imputation if dropping rows with missing data caused a significant decrease in sample size.

```{python}
# Removing any rows with missing data to clean the dataset
num_countries_before = merged_data["Country Name"].nunique()

# Drops all rows where duplicates occur
cleaned_data = merged_data.dropna() 

# 2023 had no data so the count of years goes down to 23
num_years = cleaned_data["Year"].nunique()
#print(f"Total number of unique years observed in cleaned: {num_years}")

# Allows summary of how many countries were lost
num_countries_after = cleaned_data["Country Name"].nunique()
countries_removed = num_countries_before - num_countries_after

#print(f"Number of countries before removing NAs: {num_countries_before}")
#print(f"Number of countries after removing NAs: {num_countries_after}")
#print(f"Number of countries removed: {countries_removed}")

# Ensure all columns are in the correct types
cleaned_data['Country Name'] = cleaned_data['Country Name'].astype(str)
cleaned_data['Country Code'] = cleaned_data['Country Code'].astype(str)
cleaned_data['Year'] = cleaned_data['Year'].astype('category')
cleaned_data['Heathcare Expenditure (USD)'] = cleaned_data['Heathcare Expenditure (USD)'].astype(float).round(3)
cleaned_data['Infant Mortality Rates (per 1,000 live births)'] = cleaned_data['Infant Mortality Rates (per 1,000 live births)'].astype(float).round(3)
```

**Summary Statistics**

```{python}
#Compute summary statistics
summary_stats = cleaned_data.describe().transpose()
summary_stats = summary_stats[['count', 'mean', '50%', 'std', 'min', 'max']]
summary_stats.columns = ['N', 'Mean', 'Median', 'SD', 'Min', 'Max']
summary_stats.index.name = "Variable"

# Round values for better readability and format as strings for LaTeX output
summary_stats = summary_stats.round(1).astype(str)

# Convert index to column for better formatting
summary_stats.reset_index(inplace=True)

# Convert table to LaTeX format with formatting
latex_table = summary_stats.to_latex(index=False,
                                     caption="Summary Statistics of Variables",
                                     label="Table 2:summary_stats",
                                     column_format="lrrrrrr",
                                     escape=False)

latex_table = latex_table.replace("\\begin{table}", "\\begin{table}[H]")

# Save to a LaTeX file
with open("summary_table.tex", "w") as f:
    f.write(latex_table)
```

\input{summary_table.tex}

Table 2 displays the summary statistics for healthcare expenditure (USD) and infant mortality rates (per 1,000 live births) across 4109 observations, revealing significant differences between countries.

Healthcare expenditure per Capita showed a mean of \$956.0 but a lower median of \$256.7, indicating a positivley skewed distribution where only few countries spend more. The large standard deviation (\$1,685.7) and range (\$4.0–\$12,473.8) highlight large global and temporal differences in healthcare investment.

Infant mortality rates show similar variation, with a mean of 26.9 deaths per 1,000 live births and a median of 17.7. The high standard deviation (25.0) and range (1.4–138.3) may be attributed to major differences in healthcare investment and quality.

**Distribution Analysis**

```{python}
# Healthcare Expenditure
plt.figure(figsize=(10, 4))
sns.boxplot(y=cleaned_data["Heathcare Expenditure (USD)"], color='blue')
plt.figtext(0.5, 0.03, "Figure 1: Box Plot of Healthcare expenditure Per Capita (USD)", ha="center", fontsize=11)
plt.show()

plt.figure(figsize=(10, 4))
sns.histplot(cleaned_data["Heathcare Expenditure (USD)"], bins=30, kde=True, color='blue')
plt.figtext(0.5, -0.06, "Figure 2: Histogram with Density of Healthcare expenditure Per Capita (USD)", ha="center", fontsize=11)
plt.xlabel("Healthcare expenditure Per Capita (USD)")
plt.show()
```

Figures 1 and 2 show the distribution of healthcare expenditure per capita. Figure 1 shows that healthcare expenditure is highly positively skewed, supporting the analysis from the summary statistics. The median expenditure is toward the lowers quartile, indicating that most countries have relatively little expenditure, while a few have significantly higher spending. The whiskers of the box plot are short, suggesting that a large proportion of the data is concentrated within a lower range, while the numerous outliers highlight extreme expenditure levels in some countries.

Figure 2 reiterates the positive skew of the data. Most countries have low healthcare expenditure, grouped toward the left of the axis, with just a handful having exceptionally high expenditures. The density curve (smooth blue line) shows the exponential drop in frequency as expenditure increases, emphasising that high-spending countries are exceptions rather than the rule.

```{python}
plt.rcParams.update({'font.size': 11})

# IMR
plt.figure(figsize=(10, 4))
sns.boxplot(y=cleaned_data["Infant Mortality Rates (per 1,000 live births)"], color='green')
plt.figtext(0.5, 0.03, "Figure 3: Box Plot of Infant Mortality Rate (per 1,000 live births)", ha="center", fontsize=9)
plt.show()

plt.figure(figsize=(10, 4))
sns.histplot(cleaned_data["Infant Mortality Rates (per 1,000 live births)"], bins=30, kde=True, color='green')
plt.figtext(0.5, -0.05, "Figure 4: Histogram with Density of Infant Mortality Rate (per 1,000 live births)", ha="center", fontsize=9)
plt.xlabel("Infant Mortality Rate (per 1,000 live births)")
plt.show()

plt.rcParams.update({'font.size': 14})

```

The distribution of infant mortality rate seen in Figures 3 and 4 is similar to that of healthcare expenditure per capita.

The variable is also positively skewed, as seen by the median being significantly lower than the upper quartile. There are several outliers in Figure 3, with specific countries having abnormally high infant mortality rates.

This is supported by Figure 4, which displays that as rates rise frequency falls dramatically, the majority of observations being below 40 deaths per 1,000 live births. While infant mortality is low in many nations, it is much higher in others, most likely because of infrastructural constraints, economic considerations, and healthcare discrepancies. This may indicate a causal relationship between healthcare expenditure per capita and infant mortality rate needing investigation.

**Correlation Analysis**

```{python}
numerical_data = cleaned_data.select_dtypes(include=[np.number])

# Calculate the Spearman rank correlation matrix
correlation_matrix = numerical_data.corr(method='spearman')

# Plot the heatmap
plt.figure(figsize=(10, 4))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5, square=True)
plt.figtext(0.5, -1.05, "Figure 5: Spearman Rank Correlation Matrix of Healthcare Expenditure and Infant Mortality Rates", ha="center", fontsize=14)
plt.show()
```

Figure 5 illustrates the relationship between healthcare expenditure per capita and infant mortality rates. The correlation coefficient of -0.88 indicates a strong negative correlation, suggesting that as healthcare expenditure increases, infant mortality rates decrease. This aligns with economic and public health expectations, where greater investment in healthcare typically leads to better medical infrastructure, improved care, and reduced infant deaths. Spearman's rank correlation is used as it captures non-linear relationships, making it more robust. However, correlation does not imply causation, and additional factors such as healthcare efficiency, socioeconomic disparities, and government policies could be confounders in this relationship.

**Regression Analysis**

```{python}
# Prepare data
X = cleaned_data["Heathcare Expenditure (USD)"].to_numpy(float)
y = cleaned_data["Infant Mortality Rates (per 1,000 live births)"].to_numpy(float)

y = np.log10(y)

# Create X values for smooth curve plotting
X_range = np.linspace(min(X), max(X)).reshape(-1, 1)

# Exponential Regression 
def exponential_model(x, a, b): # A = y-intercept,  B = decay rate
    return np.maximum(a * np.exp(b * x), 0)  # Limit at 0

# Estimate best values of a and b
popt, _ = curve_fit(exponential_model, X, y, p0=(1, -0.001))

# Extract the optimal values or a and b
a_exp, b_exp = popt

# Uses best a and b to predict IMR
y_pred_exp_plot = np.maximum(exponential_model(X_range.flatten(), a_exp, b_exp), 0)


# Polynomial Regression 
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X.reshape(-1, 1)) # Reshape X into a 2D array
X_range_poly = poly.transform(X_range) #Generates polynomial features
poly_model = LinearRegression().fit(X_poly, y) # fits the model using linear regression

# Get predictions and enforce a non-increasing trend
y_pred_poly = poly_model.predict(X_poly)
y_pred_poly_plot = poly_model.predict(X_range_poly)

# Generate performance metrics
r2_poly = r2_score(y, y_pred_poly)


#Logarithmic Regression
def log_model(x, a, b): # a = intercept, b = change coefficient
    return np.maximum(a + b * np.log(x + 1), 0)  # Avoid log(0) error, limit at 0

popt, _ = curve_fit(log_model, X, y, p0=(1, 1)) # finds the best fit of a and b
a_log, b_log = popt # extracts best fit variables

#generates predictions of IMR using best fit a and b
y_pred_log_plot = np.maximum(log_model(X_range.flatten(), a_log, b_log), 0) 


# Power Law Regression 
def power_model(x, a, b): # a = scaling factor, b = power exponent/rate of change
    return np.maximum(a * np.power(x, b), 0)  # Limit at 0

# Find best values of a and b
popt, _ = curve_fit(power_model, X[X > 0], y[X > 0], p0=(1, -1)) # limit values to X > 0
a_pow, b_pow = popt # extracts best fit variables

# Generate predictions
y_pred_pow = power_model(X, a_pow, b_pow)

# Generate predictions for plotting
y_pred_pow_plot = power_model(X_range.flatten(), a_pow, b_pow)

#Linear Regression (Benchmark)
linear_model = LinearRegression().fit(X.reshape(-1, 1), y)
y_pred_lin_plot = np.maximum(linear_model.predict(X_range), 0)  # Limit at 0

# Compute R2 and MAE for each model
def compute_metrics(y_true, y_pred):
    return r2_score(y_true, y_pred), mean_absolute_error(y_true, y_pred)

metrics = {
    "Exponential": compute_metrics(y, exponential_model(X, a_exp, b_exp)),
    "Logarithmic": compute_metrics(y, log_model(X, a_log, b_log)),
    "Power Law": compute_metrics(y[X > 0], power_model(X[X > 0], a_pow, b_pow)),
    "Polynomial": compute_metrics(y, poly_model.predict(X_poly)),
    "Linear": compute_metrics(y, linear_model.predict(X.reshape(-1, 1))),
}

# Plot the Regression Comparisons 
plt.figure(figsize=(10, 6))
sns.scatterplot(x=X, y=y, label="Actual Data", color="gray", alpha=0.5)

plt.plot(X_range, y_pred_exp_plot, color="red", label=f"Exponential (R²: {metrics['Exponential'][0]:.2f}, MAE: {metrics['Exponential'][1]:.2f})")
plt.plot(X_range, y_pred_poly_plot, color="blue", label=f"Polynomial (R²: {metrics['Polynomial'][0]:.2f}, MAE: {metrics['Polynomial'][1]:.2f})")
plt.plot(X_range, y_pred_log_plot, color="purple", label=f"Logarithmic (R²: {metrics['Logarithmic'][0]:.2f}, MAE: {metrics['Logarithmic'][1]:.2f})")
plt.plot(X_range, y_pred_pow_plot, color="green", label=f"Power Law (R²: {metrics['Power Law'][0]:.2f}, MAE: {metrics['Power Law'][1]:.2f})")
plt.plot(X_range, y_pred_lin_plot, color="orange", linestyle="dashed", label=f"Linear (R²: {metrics['Linear'][0]:.2f}, MAE: {metrics['Linear'][1]:.2f})")

plt.figtext(0.5, -0.01, "Figure 6: Comparison of Regression Models: Healthcare Spend vs Infant Mortality Rate", ha="center", fontsize=11)
plt.xlabel("Healthcare expenditure Per Capita (USD)")
plt.ylabel("log10(Infant Mortality Rate)")
plt.legend()
plt.show()
```

Figure 6 compares five regression models; exponential, polynomial, logarithmic, power law, and linear, in quantifying the relationship between healthcare expenditure per capita and infant mortality rates. A log10 transformation was performed to deal with the skewness of the data and reduce heteroscedasticity. All models are constrained to prevent infant mortality predictions below 0, ensuring a realistic representation. The linear model performs worst (R² = 0.45), not capturing the non-linearity of the data, indicating that non-linear regression methods may fit the relationship better.

Polynomial regression initially follows the relationship but overall performs poorly, shown by its lower R² of 0.62. Exponential and Power Law regression perform well (R² = 0.64 and 0.74, respectively), capturing the steep initial decline in infant mortality rates before plateauing at higher expenditure levels. The logarithmic model achieves the best fit with an R² of 0.78, revealing that 78% of the variance in infant mortality rates is due to healthcare expenditure per capita, and the lowest mean absoloute error (MAE) of 0.17.

This analysis proves that non-linear models, particularly power law and logarithmic regression, provide the most accurate representation of the data, reiterating the non-linearity of the relationship between healthcare expenditure per capita and infant mortality rates shown by Figure 5.

**Regression Model Evaluation**

```{python}
# Calculate residuals
residuals = y - y_pred_pow

# Residual Plot
plt.figure(figsize=(10, 4))
plt.scatter(y_pred_pow, residuals, alpha=0.5)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel('Fitted values')
plt.ylabel('Residuals')
plt.figtext(0.5, -0.07, "Figure 7: Residual Plot of Power Law Regression ", ha="center", fontsize=11)
plt.show()
```

The residuals, illustrated by Figure 7, for the logarithmic regression model indicate some issues with fit of the model. The residuals display a clear pattern rather than being randomly scattered around 0, suggesting heteroscedasticity, where the variance of residuals increases as fitted values increase. This means that the model performs well at low levels of healthcare expenditure but struggles to maintain accuracy as expenditure increases. To address these issues, applying a log transformation to the independent variable or using alternative regression techniques may help improve the model’s fit.

\newpage

**Time Series Analysis**

```{python}
# Group data and calculate mean
mean_data = cleaned_data.groupby('Year').agg({
    'Infant Mortality Rates (per 1,000 live births)': 'mean',
    'Heathcare Expenditure (USD)': 'mean'
}).reset_index()

# Rename columns for clarity
mean_data.columns = ['Year', 'Mean Infant Mortality Rates (per 1,000 live births)', 'Mean Healthcare Expenditure (USD)']

# Round the mean values to 3 decimal places
mean_data = mean_data.round(3)

# Plot the mean data on different scales
fig, ax1 = plt.subplots(figsize=(12, 5))

# Plot Mean Infant Mortality Rates
ax1.set_xlabel('Year')
ax1.set_ylabel('Mean Infant Mortality Rates (per 1,000 live births)', color='tab:blue')
line1, = ax1.plot(mean_data['Year'], mean_data['Mean Infant Mortality Rates (per 1,000 live births)'], 
                   marker='o', color='tab:blue', label='Mean Infant Mortality Rates (per 1,000 live births)')
ax1.tick_params(axis='y', labelcolor='tab:blue')

# Create a secondary y-axis
ax2 = ax1.twinx()
ax2.set_ylabel('Mean Healthcare Expenditure (USD)', color='tab:green')
line2, = ax2.plot(mean_data['Year'], mean_data['Mean Healthcare Expenditure (USD)'], 
                   marker='o', color='tab:green', label='Mean Healthcare Expenditure (USD)')
ax2.tick_params(axis='y', labelcolor='tab:green')

# Combine legends into one
lines = [line1, line2]
labels = [line.get_label() for line in lines]
fig.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=2, frameon=False)
plt.tick_params(axis='x', rotation=45)
plt.setp(ax1.get_xticklabels(), rotation=45, ha="right")

# Add figure legend
plt.figtext(0.5, -0.01, "Figure 8: Time Series Analysis of Mean Infant Mortality Rates and Healthcare Expenditure", ha="center", fontsize=14)
fig.tight_layout()

plt.show()
```

Figure 8 illustrates the non-linear negative association between mean infant mortality rates (IMR) and mean healthcare expenditure from 2000 to 2022. The trend indicates healthcare expenditure has steadily climbed, indicating greater investment in health infrastructure and services. Leading to a continual drop in IMR, reflecting these improvements in healthcare, economic development, and medical advances

An anomaly occurs in 2022 when healthcare expenditure increases disproportionately to other years and infant death rates significantly decrease. This large increases is likely due to pandemic-related expenditure, emergency health interventions, or data errors.

```{python}
plt.rcParams.update({'font.size': 55}) #changes the size of the text in plots

# Load in dataset with countries and continents
continents = pd.read_csv('Data/Continents.csv')

# Join continents to cleaned data
cleaned_data = pd.merge(cleaned_data, continents, left_on='Country Name', right_on='Country')
cleaned_data = cleaned_data.drop(columns=['Country', 'Year_y', 'Code','time'])

# Group by continent and year to compute mean values
mean_data_by_continent = cleaned_data.groupby(['Continent', 'Year_x']).agg({
    'Infant Mortality Rates (per 1,000 live births)': 'mean',
    'Heathcare Expenditure (USD)': 'mean'
}).reset_index()

# Rename columns for clarity
mean_data_by_continent.columns = ['Continent', 'Year', 'Mean Infant Mortality Rates (per 1,000 live births)', 'Mean Healthcare Expenditure (USD)']

# Define grid layout
continents = mean_data_by_continent['Continent'].unique()
nrows, ncols = 3, 2
fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(70,80))
axes = axes.flatten()

# Determine global axis limits
infant_mortality_min, infant_mortality_max = mean_data_by_continent['Mean Infant Mortality Rates (per 1,000 live births)'].min(), mean_data_by_continent['Mean Infant Mortality Rates (per 1,000 live births)'].max()
healthcare_expenditure_min, healthcare_expenditure_max = mean_data_by_continent['Mean Healthcare Expenditure (USD)'].min(), mean_data_by_continent['Mean Healthcare Expenditure (USD)'].max()

# Sets axis limits to max of each variable
def set_axes_limits(ax, ax2):
    ax.set_ylim(infant_mortality_min, infant_mortality_max)
    ax2.set_ylim(healthcare_expenditure_min, healthcare_expenditure_max)

for i, continent in enumerate(continents):
    ax = axes[i]
    continent_data = mean_data_by_continent[mean_data_by_continent['Continent'] == continent]
    
    # Plot Infant Mortality Rate
    ax.set_xlabel('Year')
    ax.set_ylabel('Mean Infant Mortality Rates (per 1,000 live births)', color='tab:blue')
    ax.plot(continent_data['Year'], continent_data['Mean Infant Mortality Rates (per 1,000 live births)'], 
            marker='o', color='tab:blue', label='Mean Infant Mortality Rates')
    ax.tick_params(axis='y', labelcolor='tab:blue')

    # Create a secondary y-axis for Healthcare Expenditure
    ax2 = ax.twinx()
    ax2.set_ylabel('Mean Healthcare Expenditure (USD)', color='tab:green')
    ax2.plot(continent_data['Year'], continent_data['Mean Healthcare Expenditure (USD)'], 
             marker='o', color='tab:green', label='Mean Healthcare Expenditure')
    ax2.tick_params(axis='y', labelcolor='tab:green')
    
    # Set uniform axis limits
    set_axes_limits(ax, ax2)
    
    # Title for each subplot
    ax.set_title(f'Time Series for {continent}')

    # Angle x axis labels
    ax.tick_params(axis='x', rotation=45)

# Adjust layout
plt.figtext(0.5, -0.01, "Figure 9: Time Series Analysis of Mean Infant Mortality Rates and Healthcare Expenditure By Continent", ha="center", fontsize=80)
plt.tight_layout()
plt.show()
plt.rcParams.update({'font.size': 14})
```

Figure 9 shows continent-specific relationships between mean IMR and mean healthcare expenditure from 2000 to 2022. The negative relationship across all continents reiterates that increasing healthcare investment has the potential to reduce infant mortality.

Asia and Africa have had considerable decreases in IMR, indicating substantial improvements in healthcare despite relatively small expenditure. Europe and North America, with larger starting expenditures, experienced lower IMR decreases, indicating diminishing returns on investment.

Healthcare expenditure rose significantly in 2022 in Europe and South America, potentially due to pandemic-related measures. This substantial rise in expenditure corresponds with an acceleration in IMR decreases, implying short-term healthcare gains.

**Conclusion**

In conclusion, there is a strong non-linear negative relationship between healthcare expenditure and infant mortality rates. Countries with higher healthcare investment generally experience lower infant mortality, though the impact varies based on economic and healthcare infrastructure factors.

The non-linear nature of this relationship indicates diminishing returns, where initial increases in spending lead to substantial improvements, but further investments yield smaller reductions in infant mortality. Regression and time-series analyses further reinforce this pattern, indicating long-term declines in infant mortality alongside growing healthcare expenditure.

Regional disparities are present, with high-income regions investing more per capita while achieving lower mortality rates, whereas lower-income regions show greater relative improvements despite lower absolute expenditure. The 2022 anomaly suggests short-term shifts in healthcare spending and outcomes, likely due to pandemic-driven policies.

While healthcare expenditure is an important driver of infant mortality rates, efficient allocation, accessibility, and policy effectiveness remain key determinants of long-term health improvements worldwide.

[Link to Github Repository = BEE2041 Data Science in Economics Assignment](https://github.com/JoshLG18/DSE-Assignment1)



```{python}
# Concatonate PDF Files
from pypdf import PdfWriter

pdfs = ['Q1+2.pdf', 'Assignment.pdf']

merger = PdfWriter()

for pdf in pdfs:
    merger.append(pdf)

merger.write("Answers.pdf")
merger.close()
```